{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# NLP_ḺAB_5_LANGUAGE_COMPUTING\n","# Understanding Operations performed on Text considered as a list\n","sent1=['I','am','in','the','NLP','session.']\n","sent2=['There','will','be','meeting','after','this','session.']\n","sent3=['Students','will','attend','the','meeting.']"],"metadata":{"id":"wQuD0pWm0Ufp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(sent1),len(sent2),len(sent3)"],"metadata":{"id":"JZPrj0_a0YcX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concatenation(Addition Operation)\n","sent1+sent2+sent3"],"metadata":{"id":"XXuHfUcJ1VfA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent3+sent1"],"metadata":{"id":"Xjg4gsXQ1wp5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Appending the text by a single word\n","sent1.append('upto')\n","sent1.append('10.30 am')\n","sent1"],"metadata":{"id":"Xs3xKctJ2CLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Recall Indexing starts from 0\n","len(sent1)\n","for word in range(len(sent1)):\n","  print(word,sent1[word])"],"metadata":{"id":"LC2zJWSD25dh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent1.index('NLP')"],"metadata":{"id":"26iyBiOY4Vav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent1[3]"],"metadata":{"id":"1RHGiiGVNaOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for word in range(len(sent3)):\n","  print(word,sent3[word])"],"metadata":{"id":"jseJqOzSTDzd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Indexing for the range[m:n]\n","sent3[2:6]"],"metadata":{"id":"mfUxCMVSNyve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Consider a saying\n","saying = ['After', 'all', 'is', 'said', 'and', 'done','more', 'is', 'said', 'than', 'done']"],"metadata":{"id":"O4PU72ttPE6S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = set(saying)"],"metadata":{"id":"DxpySPa4MceJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = sorted(tokens)\n","tokens"],"metadata":{"id":"eUES2FN4PdHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens[-2:]"],"metadata":{"id":"ZveY5zeQPhdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Index for the range[:n] and [m:] takes the words upto n-1 and from m respectively\n","sent2, sent2[:2],sent2[2:]"],"metadata":{"id":"5Uo_5UACN7LN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Original sentences\n","sent1, sent2, sent3"],"metadata":{"id":"Ep2j0OEQNFDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sorted sentences\n","sent1.sort(), sent2.sort(), sent3.sort()\n","sent1, sent2, sent3"],"metadata":{"id":"NMu4VciXMhBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a function for finding the lexical diversity\n","def lexical_diversity(text):\n","  return len(text) / len(set(text))"],"metadata":{"id":"sBe9QXb104bE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lexical_diversity(sent1)"],"metadata":{"id":"3FRMDxAr1LIV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Understanding Operations performed on Text considered as a list\n","sent1=['I','am','in','the','NLP','session.']\n","sent2=['There','will','be','meeting','after','this','session.']\n","sent3=['Students','will','attend','the','meeting.']"],"metadata":{"id":"poJocRWl-g1x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Statistical Language Computing"],"metadata":{"id":"xMMh5zlY-4_D"}},{"cell_type":"code","source":["# Statistics for language\n","import statistics\n","statistics.mean([len(sent1),len(sent2),len(sent3)])"],"metadata":{"id":"22MyW6TkNpkx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modules need to be installed and imported\n","!pip install nltk\n","import nltk\n","from nltk.tokenize import word_tokenize\n","# Import the FreqDist function\n","# More generally we can use\n","# from nltk import FreqDist or a specific library such as\n","from nltk.probability import FreqDist"],"metadata":{"id":"rlOoXbtBRH6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download necessary resources\n","nltk.download('punkt')\n","nltk.download('nps_chat')\n","nltk.download('webtext')\n","nltk.download('treebank')\n","nltk.download('gutenberg')\n","nltk.download('all')"],"metadata":{"id":"CmutUPHIAhHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure sent4 is a string, not a list\n","sent4 = 'This is an example sentence. senetence may not be the best example, but it is an example that gives a good idea of what a frequency and frequency distribution is about.'  # Re-initialize sent4 as a string"],"metadata":{"id":"9Dt0k8WwAPNS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create FreqDist object\n","fdist_sent4 = FreqDist()\n","# Verify that the variable is a string\n","print(type(sent4))\n","print(type(fdist_sent4))"],"metadata":{"id":"T9T2OhU0Az56"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_tokenize(sent4)"],"metadata":{"id":"3zV0IOGkI2WQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize the string and update the frequency distribution\n","for word in word_tokenize(sent4):\n","    fdist_sent4[word.lower()] += 1\n","print(fdist_sent4)"],"metadata":{"id":"qWIYWkuSA5Qm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To find\n","# N(): Total number of samples\n","print(\"The total number of samples is: \", fdist_sent4.N())\n","# B(): Number of bins or unique samples\n","print(\"The number of unique samples is: \",fdist_sent4.B())\n","fdist_sent4.B(),fdist_sent4.N(), fdist_sent4.N()/fdist_sent4.B()\n","# To find the ratio of total samples to unique samples:\n","ratio_total_to_unique = fdist_sent4.N() / fdist_sent4.B()\n","print(f\"The ratio of total samples to unique samples is: {ratio_total_to_unique}\")"],"metadata":{"id":"ele2-1XsJtX3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Frequencies along with the number of words: ')\n","print('Frequency','\\tNo. of Words')\n","for r in range(fdist_sent4.B()):\n","  print(r,'\\t\\t',fdist_sent4.Nr(r))"],"metadata":{"id":"WXFYFi-nMxBM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To find the ratio of the number of samples with frequency 1 to the number of samples with frequency 2\n","# you could do the following:\n","if fdist_sent4.Nr(2) > 0:\n","    ratio_nr1_to_nr2 = fdist_sent4.Nr(1) / fdist_sent4.Nr(2)\n","    print(f\"The ratio of words with frequency 1 to words with frequency 2: {ratio_nr1_to_nr2}\")\n","else:\n","    print(\"There are no words with frequency 2\")\n"],"metadata":{"id":"im1ieAN5MY2o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fdist_sent4.keys, fdist_sent4.values,fdist_sent4.items"],"metadata":{"id":"XQ_P4SgaCNPY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(fdist_sent4.keys),type(fdist_sent4.values), type(fdist_sent4.items)"],"metadata":{"id":"unPYIzPjDK4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of distinct words:',fdist_sent4.keys())\n","print('Corresponding Frequencies:',fdist_sent4.values())\n","print('Frequency Distribution of the Uniques Words(Samples) :')\n","print(fdist_sent4.keys(),fdist_sent4.values())\n","print(fdist_sent4.items())"],"metadata":{"id":"eYD9AQ9pDP_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fdist_sent4.values()"],"metadata":{"id":"qFByFi_NBFnm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fdist_sent4.items()"],"metadata":{"id":"-GHCvmzKDoPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fdist_sent4.freq('example')"],"metadata":{"id":"vcFrCUg1BJr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To get the frquency distribution where words are arranged with freq in ascending o\n","fdist_sent4.most_common()"],"metadata":{"id":"jXIEkM4hBQe-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"_Ez14EEAdfJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a DataFrame from fdist\n","# The most_common() function returns a list of tuples, each tuple containing a word and its frequency.\n","word_freq = fdist_sent4.most_common()\n","# Convert this list of tuples into a DataFrame.\n","# The columns are named 'Word' and 'Frequency'.\n","df_fdist = pd.DataFrame(word_freq, columns=['Word', 'Frequency'])"],"metadata":{"id":"3tF1HPgreRTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To get the Frequency Distributionm\n","print(df_fdist)"],"metadata":{"id":"_XD4OYTZeitx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fdist_sent4.tabulate()\n"],"metadata":{"id":"9QuMw7bbBW7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fdist_sent4.plot()"],"metadata":{"id":"tQTsmS28BbX4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To draw the graph of cumulative freq.vs no. of samples\n","fdist_sent4.plot(fdist_sent4.B(),cumulative=True)"],"metadata":{"id":"M-n3X5O5cItb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Example: Take any paragraph and demonstrate the compuattional statistical elements associated with the paragraph."],"metadata":{"id":"bAOvsfDOOvOe"}},{"cell_type":"code","source":["# Paragraph for Frequency Distribution\n","para1=['A strong leader is essential for guiding a team towards its goals.',\n"," 'Effective leaders inspire and motivate their team members and provide clear direction and expectations, and create a positive and supportive work environment.',\n"," 'They empower their team members to take ownership of their work, encourage collaboration, and resolve conflicts constructively.',\n","'Leaders also play a crucial role in recognizing and celebrating the team achievements.',\n","'Finally fostering a sense of pride and accomplishment that fuels continued success.']"],"metadata":{"id":"Op4dfJ11QKwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fdist_para1=FreqDist(para1)\n","fdist_para1"],"metadata":{"id":"sKj7xYH3QqMB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(fdist_para1)"],"metadata":{"id":"hsO4ZNjKU20u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create a vocabulory"],"metadata":{"id":"dNcgZese_N_t"}},{"cell_type":"code","source":["# Tokenize the sentences in para1 as strings and update the frequency distribution\n","for sentence in para1:\n","    # Tokenize the sentence\n","    for word in word_tokenize(sentence):\n","        fdist_para1[word.lower()] += 1 # Update the frequency distribution of each word in the sentence\n","print(fdist_para1)"],"metadata":{"id":"pjaAm-IzpLaF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_para1=list(fdist_para1.most_common())"],"metadata":{"id":"H3kWSMP-7MU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_para1[:5]"],"metadata":{"id":"iB5uILwm8Bw9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### We will use Natural Language Toolkit: Some texts for exploration in chapter 1 of the book Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.\n"],"metadata":{"id":"FR6y6wPye2io"}},{"cell_type":"code","source":["# import the book\n","from nltk.book import *\n","nltk.book.texts"],"metadata":{"id":"DOmltF_iZ8w_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.text import Text\n","from nltk.util import bigrams\n","print(\"*** Introductory Examples for the NLTK Book ***\")\n","print(\"Loading text1, ..., text9 and sent1, ..., sent9\")\n","print(\"Type the name of the text or sentence to view it.\")\n","print(\"Type: 'texts()' or 'sents()' to list the materials.\")\n","\n","text1 = Text(gutenberg.words(\"melville-moby_dick.txt\"))\n","print(\"text1:\", text1.name)\n","\n","text2 = Text(gutenberg.words(\"austen-sense.txt\"))\n","print(\"text2:\", text2.name)\n","\n","text3 = Text(genesis.words(\"english-kjv.txt\"), name=\"The Book of Genesis\")\n","print(\"text3:\", text3.name)\n","\n","text4 = Text(inaugural.words(), name=\"Inaugural Address Corpus\")\n","print(\"text4:\", text4.name)\n","\n","text5 = Text(nps_chat.words(), name=\"Chat Corpus\")\n","print(\"text5:\", text5.name)\n","\n","text6 = Text(webtext.words(\"grail.txt\"), name=\"Monty Python and the Holy Grail\")\n","print(\"text6:\", text6.name)\n","\n","text7 = Text(treebank.words(), name=\"Wall Street Journal\")\n","print(\"text7:\", text7.name)\n","\n","text8 = Text(webtext.words(\"singles.txt\"), name=\"Personals Corpus\")\n","print(\"text8:\", text8.name)\n","\n","text9 = Text(gutenberg.words(\"chesterton-thursday.txt\"))\n","print(\"text9:\", text9.name)"],"metadata":{"id":"-RuLrP9SeIXX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.book.FreqDist"],"metadata":{"id":"nmTuLDCkbLw0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The frequency(relative proportion / probability) of a sample is defined as the count of that sample divided by the total number of sample outcomes that have been recorded by this FreqDist.  \n","### The count of a sample is defined as the number of times that sample outcome was recorded by this FreqDist.  Frequencies are always real numbers in the range [0, 1]."],"metadata":{"id":"EitXyx3bXmk7"}},{"cell_type":"code","source":["fdist_text1=FreqDist(text1)\n","fdist_text1"],"metadata":{"id":"uEhpx0BzbCu5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fdist_text1.keys"],"metadata":{"id":"vVdfBo4vYyJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_text1=list(fdist_text1.most_common())\n","vocab_text1[:10]"],"metadata":{"id":"W_pJ2g2UWEec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Drawing Frequency Plots"],"metadata":{"id":"43cf7K7E57e8"}},{"cell_type":"code","source":["fdist_text1.plot()"],"metadata":{"id":"7O8anCnf6L9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To draw the graph of cumulative freq.vs no. of samples\n","fdist_text1.plot(fdist_text1.B(),cumulative=True)"],"metadata":{"id":"g9v7WaCB6L9_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Drawing Cumulative frequency plot: It is plot of cumulative freq.  for the 50 most frequently used words in text1 - Moby Dick, which\n","account for nearly half of the tokens"],"metadata":{"id":"f2IQVBdhZ_mr"}},{"cell_type":"code","source":["# To draw the graph of cumulative freq.vs no. of samples\n","fdist_text1.plot(50,cumulative=True)"],"metadata":{"id":"XRInusLQZUAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To know rare or most less frequently occuirng words called as hapaxes.\n","fdist_text1.hapaxes()"],"metadata":{"id":"SaT1O819Wjxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### To identify the long words of a text, where the set theory convention is followed to find the words from the vocabulary of the text that are more than 15 characters long.\n","### --> This means “the set of all w such that w is an element of V (the vocabulary) and w has property P.”\n"],"metadata":{"id":"gmPEuWn16uu3"}},{"cell_type":"code","source":["# First use set to identify the words in text1\n","V = set(text1)\n","V"],"metadata":{"id":"9NESzAoa7JMb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the longwords i.e. words(w) with len(w)>15\n","long_words = [w for w in V if len(w) > 15]"],"metadata":{"id":"ZnZXHO8L7UG2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the sorted list of long words\n","sorted(long_words)"],"metadata":{"id":"A4FoaGJy7Wmc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Collocations and Bigrams\n","### A collocation is a sequence of words that occur together unusually often. Thus black belt is a collocation, whereas the belt is not. A characteristic of collocations is that they are resistant to substitution with words that have similar senses; for example,white belt sounds very odd.\n","### collocations are essentially just frequent bigrams,where we pay more attention to the cases that involve rare words. In particular, we want to find bigrams that occur more often than we would expect based on the frequency of individual words."],"metadata":{"id":"QDqcq39Cbaym"}},{"cell_type":"markdown","source":["### To find collocations, we start off by extracting from a text a list of word pairs, also known as bigrams, which is done using the function bigrams():"],"metadata":{"id":"nejeGfKg9wWk"}},{"cell_type":"code","source":["from nltk.util import bigrams"],"metadata":{"id":"fDdaoAsF_HDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bigrams_text1 = list(bigrams(text1))\n","print(bigrams_text1)"],"metadata":{"id":"4NTYp8aK_Qtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(text1.collocations())"],"metadata":{"id":"o-FffFul9-7x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(text4.collocations())"],"metadata":{"id":"sL0mG4yB_7wS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lLyOGc_GUXOF"},"execution_count":null,"outputs":[]}]}